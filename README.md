<snippet>
#Tokenization
This program 'tokenizes' a body of text. Tokenization refers to splitting the text by the unique occurence of a word. Each unique word is a 'token'.

##Quick Start
More details soon to come!
</snippet>
